\documentclass{article}

\usepackage{amsmath, amsthm, amssymb, amsfonts, mathtools,enumitem, stmaryrd, physics}
\usepackage{tikz-cd}
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{tocbasic}
\usepackage{geometry}
    \geometry{
        a4paper,
        left = 40mm,
        top = 20mm,
        right = 40mm,
        bottom = 30mm
    }
\setlength{\parindent}{0pt}

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem*{example}{Example}
\newtheorem*{exercise}{Exercise}
\newtheorem*{definition}{Definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{theorem*}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{proposition*}{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{lemma*}{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{corollary*}{Corollary}
\newtheorem*{remark}{Remark}
\newtheorem*{construction}{Construction}

\newcommand{\Frac}{\operatorname{Frac}}
\newcommand{\im}{\operatorname{im}}
\newcommand{\acts}{\circlearrowright}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\Char}{\operatorname{char}}
\renewcommand{\span}{\operatorname{span}}
\newcommand{\ad}{\operatorname{ad}}

\title{Number Theory Reading Group}
\author{Thanic Nur Samin}
\date{\vspace{-5ex}}

\begin{document}

\maketitle

\tableofcontents

\section{Thursday, 9/12/2024, Representation of \(\mathfrak{sl}_2(\mathbb{F})\) by Hechi}

\[
    \mathfrak{sl}_2(\mathbb{F}) \coloneqq \{ g \in \mathfrak{gl}_2(\mathbb{F}) \mid \Tr(g) = 0 \}
\]

We assume \(\Char(\mathbb{F}) = 0\) and \(\mathbb{F}\) is algebraically closed.

\begin{theorem}
    \(\mathfrak{sl}_2(\mathbb{F})\) is semisimple
\end{theorem}

\begin{proof}
    Direct computation of the Killing Form.
\end{proof}

Recall: if \(\mathfrak{L}\) is semisimple and \(\phi: \mathfrak{L}  \to \mathfrak{gl}(V)\) is a representation.

\(\mathfrak{L} \ni x = s+n\) abstract jordan decomposition.

\(\implies \phi(x) = \phi(s) + \phi(n)\) is the Jordan decomposition of \(\phi(x)\) in \(\phi(\mathfrak{L})\).

From now on, \(\mathfrak{L} = \mathfrak{sl}_2(\mathbb{F}) = \mathfrak{sl}(2,\mathbb{F})\).

\((V,\phi)\) is a representation.

Basis of \(\mathfrak{L}\):

\[
    x = \begin{bmatrix}
        0 &  1 \\
        0 &  0 \\
    \end{bmatrix}
\]

\[
    y = \begin{bmatrix}
        0 &  0 \\
        1 &  0 \\
    \end{bmatrix}
\]

\[
    h = \begin{bmatrix}
        1 &  0 \\
        0 &  -1 \\
    \end{bmatrix}
\]

Thus we have \([h,x] = 2x, [h,y]=-2y, [x,y]=h\). 

Since \(h\) is diagonal, \(h\) is semisimple.

\(\implies \phi(h)\) is semisimple and thus diagonalizeable. \(\in \End(V)\). 

We can decompose \(V = \bigoplus_{\lambda} V_\lambda\) where \(V_\lambda = \{ v\in V \mid h v = \lambda v \} \) for all \(\lambda \in \mathbb{F}\). 

We say \(V_\lambda\) is a \underline{weight space} with \(\lambda\) as its weight.

\begin{lemma}
    [7.1] Suppose \(v\in V_\lambda\). Then,

    \begin{enumerate}[label=\arabic*)]
        \item \(xv \in V_{\lambda+2}\)
        \item \(yv \in V_{\lambda-2}\) 
    \end{enumerate} 
\end{lemma}

\begin{proof}
    \begin{enumerate}[label=\arabic*)]
        \item \(h(xv) = [h,x]v + x(hv) = 2xv + \lambda xv = (\lambda + 2)xv\)
        \item \(h(yv) = [h,y]v + y(hv) = -2yv + \lambda yv = (\lambda - 2)yv\)  
    \end{enumerate} 
\end{proof}

\begin{center}
    \begin{tikzcd}
        V_{\lambda-2} & V_{\lambda} \ar[l, bend left, "y", swap] \ar[r, bend right, "x", swap] \ar[loop, "h", swap] & V_{\lambda+2}
    \end{tikzcd}
\end{center}

Note that \(\dim V < \infty\)

Thus, \(\exists v \in V\) such that \(x\cdot v = 0\).

Such a \(v\) is called a \underline{maximal vector}. 

For now, assume \(V\) is irreducible.

Let \(v_0\) be a maximal vector with weight \(\lambda\).

\begin{definition}
    For \(i > 0\) integer, \(v_i = \frac{y^i\cdot v_0}{i!}\) 

    Also, \(v_{-1}=0\).
\end{definition}

\begin{lemma}
    [7.2]

    \begin{enumerate}[label=\arabic*)]
        \item \(h\cdot v_i = (\lambda - 2i)v_i\) 
        \item \(y\cdot v_i = (i+1)v_{i+1}\)
        \item \(x\cdot v_i = (\lambda - i + 1) v_{i-1}\)  
    \end{enumerate} 
\end{lemma}

\begin{proof}
    \begin{enumerate}[label=\arabic*)]
        \item We use induction. Base case is clear.
        
        Assume it is true for \(i-1\). 

        \(v_{i-1} \in V_{\lambda - 2(i-1)}\) 

        Thus, \(v_i = \frac{1}{i} \cdot y v_{i-1}\)
        
        Lemma 7.1 implies \(v_i \in V_{\lambda - 2i}\).

        \item \(y\cdot v_i = (i+1) v_{i+1}\) by definition of \(v_i\). 
        
        \item \(i x\cdot v_i = x (yv_{i-1}) = [x,y]v_{i-1} + yx v_{i-1} = h v_{i-1} + y x v_{i-1} = (\lambda - 2(i-1))v_{i-1} + (\lambda -i + 2)y v_{i-2} = i(\lambda -i + 1)v_{i-1}\) 
    \end{enumerate} 
\end{proof}

\(\dim V < \infty\) so it must end at some point.

So, at some point, it'll become \(0\). \(v_0, \cdots ,v_m \neq 0, v_{m+1} = 0\).

\begin{definition}
    \(m\) is the integer so that \(v_m \neq 0, v_{m+1} = 0\).
\end{definition}

By Lemma 7.2,

\(\span \{v_0, \cdots , v_m\}\) is a sub-representation of \(V\).

Since \(V\) is irreducible,

\(V = \span \{v_0, \cdots , v_m\}\) 

\underline{Note}: by 7.2(3),

\(0 = x \cdot v_{m+1} = (\lambda - m) v_m\) 

Since \(v_m \neq 0\) we have \(\lambda = m\).

Thus, \(\dim V = m+1 = \lambda + 1\)

Here \(m\) is the \underline{highest weight}. 

\[
    V = V_{-m} \oplus V_{-m + 2} \oplus \cdots \oplus V_{m-2} \oplus V_m
\]

\begin{construction}
    Suppose \(L \curvearrowright \mathbb{F}[X,Y]\) [as a \(\mathbb{F}\)-space].
    
    \(\rho (x) = X \frac{\partial}{\partial Y} \) 

    \(\rho (y) = Y \frac{\partial}{\partial X} \)
    
    \(\rho (h) = x \frac{\partial}{\partial x} - y \frac{\partial}{\partial y}\)
    
    Consider subrepresentations \(\mathbb{F} [X,Y]_m\) [symmetric polynomials of degree \(m\), dimension \(m+1\)].

    \begin{center}
        \begin{tikzcd}
            0 & X^m \ar[l, bend left, "x", swap] \ar[r, bend right, "y", swap] \ar[loop, "h", swap] & X^{m-1}Y & \cdots
        \end{tikzcd}
    \end{center}

\end{construction}

\newpage

\section{Thursday, 9/19/2024, Representation of \(\mathfrak{sl}_2(\mathbb{F})\) by Hechi}

\subsection*{Root Space Decomposition}

Let \(\mathcal{L}\) be a non-zero semisimple lie algebra over \(\mathbb{F}\) with \(\Char \mathbb{F} = 0\) and \(\mathbb{F}\) algebraically closed.

\begin{definition}[Toral Subalgebra]
    A subalgebra \(\mathcal{H} \subseteq \mathcal{L}\) \underline{toral} if it consists of semisimple elements.
\end{definition}

\begin{remark}
    If every element in \(\mathcal{L}\) is ad-nilpotent, then by Engel's Theorem \(\mathcal{L}\) is nilpotent. Thus it is not semisimple. 

    So, there exists a non-zero toral subalgebra.
\end{remark}

Fix \(\mathcal{H}\) to be the \underline{maximal toral subalgebra}. A maximal subalgebra exists since \(\mathcal{L}\) is finite dimensional.

\begin{lemma}
    [8.1] A toral subalgebra \(\mathcal{T}\) is abelian.
\end{lemma}

\begin{proof}
    Suppose \(x\in \mathcal{T}\). We will prove that \(\ad_{\mathcal{T}}x = 0\) [as a map].

    \(\ad_T x\) is diagonalizeable. Assume some eigenvalue is non-zero. Then, we can find eigenvactor \(y\in T\) with eigenvalue \(a \neq 0\). So, \([x,y]=ay\).

    Now, \(\ad_T y (x) = [y,x] = -ay\). Since \([y,y]=0\) we see that \(-ay\) is an eigenvector of \(\ad_T y\) with eigenvalue \(0\). 

    \(\ad_T y\) is also diagonalizeable. Suppose \(v_1, \cdots , v_n\) is the eigenbasis of \(\ad_T y\) with eigenvalues \(\lambda_1, \cdots , \lambda_n\). Then \(x = a_1 v_1 + \cdots + a_n v_n\) for \(a_i \in \mathbb{F} \).

    WLOG, \(v_1 = y\).

    \[
        [y,x] = a_1 \lambda _1 v_1 + \cdots + a_n \lambda_n v_n = -ay
    \]

    By comparing coefficients, \(a_1 \lambda _1 = -a\). But \(\lambda_1 = 0\). This is a contradiction. 

\end{proof}

Now, we fix \(\mathcal{H}\) to be a maximal toral subalgebra. It is not necessarily unique.

Note that \(\ad H\) is a \underline{commuting family} in \(\End(\mathcal{L})\). From linear algebra we know that \(\ad H\) is \underline{simultaneously diagonalizeable}.

\begin{definition}
    [Root Space Decomposition]
    Suppose \(\mathcal{H} ^{\ast} \) is the dual space of \(\mathcal{H}\). We can write:

    \[
        \mathcal{L} = \bigoplus_{\alpha \in H^{\ast}} \{ x \in \mathcal{L} \mid [h,x] = \alpha (h) x \forall h\in H \}
    \]

    \[
        = \mathcal{L}_0 \oplus \bigoplus_{\alpha \in \Phi} \mathcal{L} \alpha 
    \]

    where \(\Phi = \{ \alpha \in H^{\ast} \setminus \{ 0 \}  \mid  \mathcal{L} \alpha \neq 0\} \) and \(\mathcal{L} _0 = C_{\mathcal{L}}(\mathcal{H})\) [the centralizer]. 

    This is called the \underline{root space decomposition}. 

\end{definition}

\begin{example}
    \(\mathfrak{sl}_2(\mathbb{F})\) has basis:

    \[
        x = \begin{bmatrix}
            0 &  1 \\
            0 &  0 \\
        \end{bmatrix}, y = \begin{bmatrix}
            0 &  0 \\
            1 &  0 \\
        \end{bmatrix}, h = \begin{bmatrix}
            1 &  0 \\
            0 &  -1 \\
        \end{bmatrix}
    \]

    Then the root space decomposition is:

    \[
        \mathfrak{sl}_2(\mathbb{F}) = \mathcal{H} \oplus \mathcal{L}_{-2} \oplus \mathcal{L}_{2}
    \]

    \(\mathcal{L}_{-2}\) contains the linear form sending \(h\) to \(-2\). 

\end{example}

\begin{proposition}
    [8.1] Let \(\alpha , \beta \in \mathcal{H} ^{\ast}\). Then,

    \begin{enumerate}[label=\arabic*)]
        \item \([L_\alpha , L_\beta] \subseteq L_{\alpha + \beta}\) [by Jacobi Identity]
        \item \(\alpha \neq 0 \implies \forall x\in L_\alpha\) is nilpotent [by 1]
        \item \(\alpha + \beta \neq 0 \implies L_\alpha \perp L_\beta\) w.r.t.\ the \underline{Killing Form}. 
    \end{enumerate} 
\end{proposition}

\begin{proof}
    [Proof of 3] Find \(h\in \mathcal{H}\) such that \((\alpha + \beta)(h) \neq 0\). Then,

    \[
        \kappa([h,x],y) = - \kappa([x,h],y) = - \kappa(x,[h,y])
    \]

    \[
        \implies (\alpha+\beta)(h)\kappa(x,y) = 0
    \]
\end{proof}

In particular, \(L_0 \perp L_\alpha\) when \(\alpha \in \Phi\). 

\begin{corollary}[8.1]
    The Killing Form restricted to \(\mathcal{L}_0\), \(\kappa|_{\mathcal{L}_0}\) is non-degenerate. 
\end{corollary}

\begin{proposition}
    [8.2] \(\mathcal{H} = \mathcal{L}_0 = C_{\mathcal{L}}(\mathcal{H})\).
\end{proposition}

\begin{proof}
    Tedious linear algebra
\end{proof}

\begin{corollary}
    [8.2] The Killing Form restricted to \(\mathcal{H}\), \(\kappa |_{\mathcal{H}}\) is non-degenerate.
\end{corollary}

This implies, the map \(H \to H^{\ast}\) given by \(x \mapsto \kappa (x,-)\) is an \underline{isomorphism}.

For each \(\phi \in \mathcal{H} ^{\ast}\) we can define \(t_{\phi} \in \mathcal{H} \) to be the pre-image of this isomorphism. So it satisfies

\[
    \phi(h) = \kappa (t_{\phi}, h) \quad \forall h\in \mathcal{H}
\]

\begin{proposition}
    [8.3]

    \begin{enumerate}[label=\arabic*)]
        \item \(\Phi\) spans \(\mathcal{H} ^{\ast}\) 
        \item If \(\alpha \in \Phi\) then \(-\alpha \in \Phi\)
        \item \(x\in \mathcal{L}_\alpha, y\in \mathcal{L}_{-\alpha} \implies [x,y] = \kappa (x,y)t_\alpha\)
        \item \(\alpha(t_\alpha) = \kappa (t_\alpha , t_\alpha) \neq 0\) 
        \item \(\dim [\mathcal{L}_\alpha, \mathcal{L}_{-\alpha}] = 1\), spanned by \(t_\alpha\)  
        \item Pick any non-zero \(x_\alpha\in L_\alpha \setminus \{ 0 \}\). Then there exists \(y_\alpha \in \mathcal{L}_{-\alpha}\) such that \(x_\alpha , y_\alpha , h_\alpha \coloneqq [x_\alpha , y_\alpha]\) spans a subalgebra isomorphic to \(\mathfrak{sl}_2(\mathbb{F})\), with the isomorphism \(x_\alpha \mapsto x, y_\alpha \mapsto y, h_\alpha \mapsto h\) 
        \item \(h_\alpha = \frac{2 t_\alpha}{\kappa (t_\alpha , t_\alpha )}\).  
    \end{enumerate} 
\end{proposition}

If \(V\) is a \(\mathfrak{sl}_2(\mathbb{F})\)-module, recalling that \(h = \begin{bmatrix}
    1 &  0 \\
    0 &  -1 \\
\end{bmatrix}\),

\[
    V = \bigoplus_{\lambda \in \mathbb{F}} V_\lambda \text{ eigenspaces of } h
\]

Recall that all \(\mathfrak{sl}_2(\mathbb{F})\)-module is of the form:

\[
    \mathfrak{sl}_2(\mathbb{F}) \curvearrowright \mathbb{F} [X,Y]
\]

\[
    \rho (x) = X \frac{\mathrm{d}}{\mathrm{d}Y}, \rho (y) = Y \frac{\mathrm{d}}{\mathrm{d}X} , \rho (h) = X \frac{\mathrm{d}}{\mathrm{d}X} - Y \frac{\mathrm{d}}{\mathrm{d}Y}  
\]

and \(V = \mathbb{F} [X,Y]_m\) [homogeneous polynomials of degree \(m\)] is irreducible and give us all irreducible representations. 

Then we have:

\[
    V = V_{-m} \oplus V_{-m + 2} \oplus \cdots \oplus V_{m-2} \oplus V_{m}
\]

Where \(V_m\) is generated by \(X^m\) and \(V_{-m}\) is generated by \(Y^m\) 

\begin{center}
    \begin{tikzcd}
        Y^m \ar[r, bend right, "x", swap] & X Y^{m-1} \ar[l, bend right, "y", swap] \ar[loop, "h", swap] & \cdots & X^m
    \end{tikzcd}
\end{center}

If \(m\) even, \(0 \neq V_0 \subseteq V\)

If \(m\) odd, \(0 \neq V_1 \subseteq V\)

\begin{corollary}
    \(V\) is a \(\mathfrak{sl}_2(\mathbb{F})\)-module. Then \(\dim V_0 + \dim V\) gives the number of summands in the irreducible decomposition of \(V\).
\end{corollary}

Consider \(\mathcal{S}_\alpha = \span\{ x_\alpha , y_\alpha , h_\alpha  \} \cong \mathfrak{sl}_2(\mathbb{F})\) and its adjoint representation (\(\mathcal{L}\) is an \(\mathcal{S}_\alpha\) module).

Fix \(\alpha \in \Phi \) and let \(\mathcal{M} = \mathcal{H} + \sum_{c\in \mathbb{F} ^\times } \mathcal{L}_{c \alpha}\). 

By proposition 8.1, \(\mathcal{M}\) is a submodule of \(\mathcal{L}\) [since \([\mathcal{L}_{c_1 \alpha}, \mathcal{L}_{c_2 \alpha}] \subseteq \mathcal{L}_{(c_1 + c_2)\alpha}\)].

If \(0 \neq x \in \mathcal{L}_{c \alpha}\) we see that \([h_\alpha , x] = c \alpha (h_\alpha)\cdot x = 2 c x\) 

\(\implies\) \(2c\in \mathbb{Z}\) and a \(\underbrace{\text{weight}}_{\text{eigenvalue}}\) of \(h_\alpha\) is \(0\) or an integer multiple of \(\frac{1}{2}\).

Then \(\mathcal{M} = \underbrace{\ker \alpha}_{\text{vectors of weight } 0} + \underbrace{\mathbb{F} \cdot h_\alpha}_{\text{weight } 0, \pm 2}\) 

Therefore, \(\mathcal{M}\) contains vectors of weight only \(0\) or \(\pm 2\). 

Therefore, if \(\alpha \in \Phi\) we have \(c = \pm 1\).

\(\mathcal{M} = \mathcal{H} + \mathcal{S}_\alpha\). Suppose \(h_\alpha ^c \) is the complement of \(h_\alpha\) in \(\mathcal{H} \). 

Then, \(\mathcal{H} + \mathcal{S}_\alpha = \underbrace{h_\alpha^c}_{\text{abelian}} + \underbrace{\mathcal{S}_\alpha}_{\text{irreducible}}\) has \(\dim \mathcal{H} - 1 + 1 = \dim \mathcal{H} = \dim \mathcal{M} - 2\) irreducible summands.

On the other hand, the number of irreducible summands of \(\mathcal{M}\) is \(\underbrace{\dim \mathcal{M}_0}_{\dim \mathcal{M} - 2} + \underbrace{\dim \mathcal{M}_1}_{0}\) 

Therefore, \(\mathcal{H} + \mathcal{S}_\alpha \subseteq \mathcal{M}\) must be \underline{equal}.

Therefore, \(\dim \mathcal{L}_\alpha = 1\).

Now, suppose \(\beta \neq \pm \alpha \in \Phi\). Then, \(\exists r,q\) such that \(\beta - r \alpha , \beta - (r-1)\alpha , \cdots , \beta + q \alpha\) are roots and outside outside these, i.e.\ \(\beta - (r+1)\alpha , \beta + (q+1)\alpha\) are not.

To see this, suppose \(K = \sum_{i\in \mathbb{Z}}^{} \mathcal{L}_{\beta + i \alpha} \subseteq \mathcal{L}\) is a \(\mathcal{S}_\alpha\)-submodule. We know that \(\beta + i \alpha \neq 0\).

Weights:

\[
    \beta(h_\alpha) + i \alpha (h_\alpha) = \beta (h_\alpha) + 2i
\]  

So, weights are either all even or all odd.

Therefore, \(K\) is irreducible.

Consider \(\gamma , \delta \in \mathcal{H} ^{\ast}\).

Define \((\gamma , \delta) = \kappa (t_\gamma , t_\delta)\) on \(E_\mathbb{Q} = \span_\mathbb{Q} (\Phi)\) then \((\cdot,\cdot)\) extends to \(E = E_\mathbb{Q} \otimes _\mathbb{Q} \mathbb{R} \) is positive definite.

Then \(E\) is an Euclidean Space.

\[
    (\Phi, E) \text{ is called a \underline{root system}}.
\]

\newpage

\section{Thursday, 9/26/2024, Root Systems by Zoia}

Let \(E\) be an euclidean space. Suppose \((\alpha ,\beta)\) is a symmetric bilinear form on \(E\).

Reflection in \(E\) fixes some hyperplane \(H\). If \(\alpha\) is perpendicular to \(H\) then the reflection sends \(\alpha\) to \(-\alpha\) 

Consider \(\alpha \in E\) and \(P_\alpha = \{ \beta \in E \mid (\alpha , \beta) = 0 \} \) the hyperplane perpendicular to \(\alpha\). Suppose \(\sigma_\alpha\) is the reflection w.r.t.\ this hyperplane. Then,

\[
    \operatorname{proj}_\alpha (\beta) = \frac{(\beta , \alpha)}{(\alpha , \alpha)}\alpha 
\]

\[
    \sigma_\alpha (\beta) = \beta - 2 \operatorname{proj}_\alpha(\beta) = \beta - 2\frac{(\beta,\alpha)}{(\alpha ,\alpha)}\alpha
\]

Define:

\[
    \langle \beta , \alpha  \rangle = 2 \frac{(\beta,\alpha)}{(\alpha,\alpha)}
\]

Note that \(\langle \beta ,\alpha  \rangle \) is linear only in \(\beta \). Then, 

\[
    \sigma_\alpha (\beta) = \beta - \langle \beta ,\alpha  \rangle \alpha 
\]

\begin{lemma}
    Let \(\Phi\) be a finite subset of \(E\) so that \(\Phi\) spans \(E\). Suppose all reflections \(\sigma_\alpha (\alpha \in \Phi)\) leaves \(\Phi\) invariant. If \(\sigma\in \operatorname{GL}(E)\) fixes hyperplane \(P\) of \(E\) and sends \(0 \neq \alpha \in \Phi\) to \(-\alpha\), then \(\sigma = \sigma_\alpha\) and \(P = P_\alpha\).
\end{lemma}

\begin{proof}
    Suppose \(\tau = \sigma \sigma_\alpha = \sigma \sigma _\alpha ^{-1} \).

    Then, \(\tau(\Phi) = \Phi , \tau (\alpha ) = \alpha\) and \(\tau\) acts as \(\operatorname{id}\) on \(\mathbb{R} \cdot \alpha\) and \(E / R\cdot \alpha\) eigenvalues are \(1\). So we have \((T-1)^L\) where \(L = \dim E\).
    
    \(\beta , \tau (\beta), \dots \tau^k(\beta)\) \(\exists k\) that fixes all \(\beta \in \Phi \) 

    \(\Phi\) spans \(E\), so \(\tau ^ k = 1\). So \(T^k - 1 = 0\).

    If \(m(T)\) is the minimal polynomial of \(\tau\), then:

    \[
        m(T) \mid T^k - 1
    \]

    \[
        m(T) \mid (T-1)^k
    \]

    Therefore, \(m(T) = T - 1\).
    
    Therefore, \(\tau = \operatorname{id}\).

    Thus \(\sigma \sigma_\alpha ^{-1} = \operatorname{id} \implies \sigma = \sigma_\alpha \) 
\end{proof}

\begin{definition}
    [Root Systems]

    A finite subset \(\Phi\) of \(E\) is a root system in \(E\) if:

    \begin{enumerate}[label=\arabic*R)]
        \item \(\Phi\) spans \(E\), does not contain \(0\).
        \item If \(\alpha \in \Phi\) then only multiples of \(\alpha\) in \(\Phi\) are \(\pm \alpha\).
        \item If \(\alpha \in \Phi\), then \(\sigma_\alpha\) leaves \(\Phi\) invariant. \([\forall \beta \in \Phi, \sigma_\alpha (\beta)\in \Phi ]\) 
        \item If \(\alpha ,\beta \in \Phi \) then \(\langle \beta , \alpha  \rangle \in \mathbb{Z} \). \(\left[ \langle \beta , \alpha  \rangle = \frac{2(\beta,\alpha)}{(\alpha ,\alpha )} \right] \) 
    \end{enumerate} 
\end{definition}

\begin{definition}
    [Weyl Group]

    Let \(\Phi\) be a root system in \(E\). Denote by \(\mathcal{W}\) the subgroup of \(\operatorname{GL}(E)\) generaed by \(\sigma_\alpha (\alpha \in \Phi)\). 

    3R \(\implies\) \(\mathcal{W}\) is a symmetry group on \(\Phi\). 
\end{definition}

\begin{lemma}
    Let \(\Phi\) be a root system in \(E\) with Weyl group \(\mathcal{W}\). If \(\sigma \in \operatorname{GL}(E)\) leaves \(\Phi\) invariant, then \(\sigma \sigma_\alpha \sigma ^{-1} = \sigma_{\sigma (\alpha)} \forall \alpha \in \Phi\) and \(\langle \beta ,\alpha  \rangle = \langle \sigma(\beta), \sigma(\alpha) \rangle \forall \alpha ,\beta \in \Phi \).
\end{lemma}

\begin{proof}
    \(\sigma \sigma_\alpha \sigma ^{-1} (\sigma (\beta )) = \sigma \sigma_\alpha (\beta) = \sigma(\beta - \langle \beta ,\alpha  \rangle \alpha ) = \sigma(\beta) - \langle \beta ,\alpha  \rangle \sigma(\alpha)\).

    \(\sigma(\beta)\) runs over \(\Phi\). \(\sigma \sigma_\alpha \sigma ^{-1}\) fixes \(\sigma(P_\alpha)\) pointwise and \(\sigma(\alpha) \to -\sigma(\alpha)\). 

    Therefore, \(\sigma \sigma_\alpha \sigma ^{-1} = \sigma_{\sigma(\alpha)}\) by the lemma.

    \(\sigma_{\sigma(\alpha)}(\sigma(\beta)) = \sigma(\beta) - \langle \sigma(\beta), \sigma(\alpha) \rangle \sigma(\alpha)\) 

    Therefore, we must have \(\langle \beta , \alpha \rangle = \langle \sigma(\beta) , \sigma(\alpha ) \rangle \). 
\end{proof}

\begin{definition}
    [Isomorphisms] Suppose \(\Phi, \Phi ^{\prime} \) are root systems with Euclidean spaces \(E, E^{\prime}\).

    \((\Phi , E) \cong (\Phi ^{\prime} , E^{\prime} )\) if there exists map \(\varphi: E \to E^{\prime}\) such that \(\varphi\) maps \(\Phi\) to \(\Phi ^{\prime} \) and \(\forall \alpha ,\beta \in \Phi\) we have \(\langle \varphi(\beta), \varphi(\alpha) \rangle = \langle \beta , \alpha \rangle \).
\end{definition}

Note that:

\[
    \sigma_{\varphi(\alpha)}(\varphi(\beta)) = \varphi(\beta) - \underbrace{\langle \varphi (\beta), \varphi(\alpha) \rangle }_{=\langle \beta ,\alpha  \rangle} \varphi (\alpha) = \varphi (\beta - \langle \beta ,\alpha  \rangle \alpha) = \varphi (\sigma_\alpha (\beta))
\]

Note that, \(\sigma \mapsto \varphi \sigma \varphi ^{-1} \) is an isomorphism of Weyl groups.

Thus, \(\mathcal{W}\) is a subgroup of \(\operatorname{Aut} (\Phi )\).

Now we consider root systems of different dimensions. Suppose \(L = \dim E\).

\underline{\(L = 1\)}: In this case, we have \(\alpha ,\alpha \in \Phi \) only. This gives us \(A_1\) 

\begin{center}
    \begin{tikzpicture}
        \draw[<->] (0,0.5)--(2,0.5);
        \node at (1,0.5)[circle,fill,inner sep = 1]{};
    \end{tikzpicture}

    \(A_1\) 
\end{center}

\(\mathcal{W} (A_1) = \mathbb{Z}_2\) 

\underline{\(L = 2\)}:

\begin{center}
    \includegraphics[width=0.9\textwidth]{img/root_systems}
\end{center}

\(\mathcal{W}(A_1 \times A_1) = \mathbb{Z}_2 \times \mathbb{Z}_2\) 

\(\mathcal{W} (A_2) = S_3\) 

\(\mathcal{W}(B_2) = D_4\) 

\(\mathcal{W}(G_2) = D_6\) 

These are the only possible cases for \(L=2\), since:
\[
    \langle \beta , \alpha  \rangle = \frac{2(\beta,\alpha)}{(\alpha,\alpha)} = \frac{2 \lVert \beta  \rVert \lVert \alpha  \rVert \cos \theta}{\lVert a \rVert \lVert a \rVert } = \frac{2 \lVert \beta  \rVert}{\lVert \alpha  \rVert} \cos \theta \in \mathbb{Z}
\]

Similarly, \(\frac{2 \lVert \alpha \rVert }{\lVert \beta  \rVert }\cos \theta \in \mathbb{Z}\). Multiplying, \(4 \cos^2 \theta \in \mathbb{Z} \implies 4\cos^2\theta = 0,1,2,3,4 \)

Thus, \(\cos \theta = 0, \pm\frac{1}{2}, \pm\frac{1}{\sqrt{2}}, \pm\frac{\sqrt{3}}{2} \implies \theta = \frac{\pi}{2}, \frac{\pi}{3}, \frac{2\pi}{3}, \frac{\pi}{4}, \frac{3\pi}{4}, \frac{\pi}{6}, \frac{5\pi}{6}\).

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c}
        \toprule
            \(\langle \alpha , \beta \rangle \) & \(\langle \beta , \alpha \rangle \)  & \(\theta\) &  \(\lVert \beta  \rVert ^2 / \lVert \alpha \rVert ^2\)  \\
        \midrule
            0 & 0 & \(\frac{\pi}{2}\) & undefined \\
            1 & 1 & \(\frac{\pi}{3}\) & 1  \\
            -1 & -1 & \(\frac{2\pi}{3}\) & 1 \\
            1 & 2 & \(\frac{\pi}{4}\) & 2 \\
            -1 & -2 & \(\frac{3\pi}{4}\) & 2  \\
            1 & 3 & \(\frac{\pi}{6}\)  & 3 \\
            -1 & -3 & \(\frac{5\pi}{6}\) & 3 \\
        \bottomrule
    \end{tabular}
    \caption{Angle Root System}
    \label{tab:rootsystable}
\end{table}

\begin{lemma}
    Suppose \(\alpha ,\beta \) are non-proportional root.
    
    If \((\alpha ,\beta) > 0\) then \(\alpha  - \beta \) is a root.

    If \((\alpha ,\beta ) < 0\) then \(\alpha + \beta \) is a root.

\end{lemma}

\begin{proof}
    \(\langle \alpha ,\beta  \rangle = 1 \implies \sigma_\beta (\alpha) = \alpha - 1\beta = \alpha - \beta  \in \Phi\) 

    If \(\langle \beta ,\alpha  \rangle = 1\) then \(\sigma_\alpha(\beta) = \beta - 1\alpha = \beta -\alpha \in \Phi\).
    
    \(\sigma_{\beta - \alpha}(\beta - \alpha) = (\beta - \alpha) - \langle \beta -\alpha , \beta -\alpha  \rangle (\beta -\alpha ) = \alpha - \beta \in \Phi\) 
\end{proof}

\section{Thursday, 10/3/2024, Simple Roots by Zoia}

A root system \(\Phi\) of rank \(l\), \(E\)-Euclidean Space, \(\mathcal{W}\) is the Weyl Group.

\begin{definition}
    A subset \(\Delta\) of \(\Phi\) is called a \underline{base} if:

    \begin{enumerate}[label=B\arabic*)]
        \item \(\Delta\) is a basis of \(E\) [\(\vert \Delta \vert = l\)];
        \item \(\forall \beta \in \Phi , \beta = \sum_{\alpha \in \Delta} k_\alpha \cdot \alpha\), the expression is unique with \(k_\alpha\) being integers and \(k_\alpha\) are either all non-negative or all non-positive. 
    \end{enumerate} 
\end{definition}

\begin{definition}
    The roots from \(\Delta\) are \underline{simple roots}.
\end{definition}

\begin{definition}
    The \underline{height} of a root \(\beta\) [relative to the base \(\Delta\)] is:

    \[
        \operatorname{ht} (\beta) = \sum_{\alpha \in \Delta} k_\alpha
    \]
\end{definition}

\begin{definition}
    We have \underline{positive roots} \(\Phi^+\) and negative roots \(\Phi^-\) from the sign of \(k_\alpha\). Furthermore \(\Phi^- = - \Phi^+\).

    Also, we define:

    \[
        \Phi^+(\gamma) = \{ \alpha \in \Phi \mid (\gamma , \alpha) > 0 \}
    \]
\end{definition}


\begin{definition}
    \(\gamma \in E\) is regular if:

    \[
        \gamma \in E \setminus \bigcup_{\alpha \in \Phi}^{} P_\alpha
    \]

    Otherwise it is called singular.

    Recall that \(P_\alpha =\{ \beta \in E \mid (\alpha ,\beta) = 0 \}\)
\end{definition}

\begin{definition}
    \(\alpha \in \Phi^+(\gamma)\) is \underline{decomposable} if \(\alpha = \beta_1 + \beta_2\) with \(\beta_1, \beta_2 \in \Phi^+(\gamma)\). 
    
    \(\alpha\) is \underline{indecomposable} otherwise.
\end{definition}

\begin{definition}
    We define \(\Delta (\gamma)\) to be the set of all indecomposable roots in \(\Phi^+(\gamma)\).
\end{definition}

\begin{theorem}
    Any root system \(\Phi\) has a base. Let \(\gamma \in E\) be a \underline{regular}.

    Then, the set \(\Delta (\gamma)\) of all the indecomposable roots in \(\Phi^+(\gamma)\) is a base of \(\Phi\). 

    Conversely, every base of \(\Phi\) is of the form \(\Delta(\gamma)\) for some \(\gamma\).
\end{theorem}

\begin{proof}
    We follow the following steps.
    
    \underline{Step 1}: Each root in \(\Phi^+(\gamma)\) is a non-negative \(\mathbb{Z}\)-linear combination of \(\Delta(\gamma)\). 

    \underline{Step 2}: If \(\alpha , \beta \in \Delta (\gamma)\) then \((\alpha , \beta) \leq 0\) unless \(\alpha = \beta\). 

    \underline{Step 3}: \(\Delta (\gamma)\) is a linearly independent set.

    \underline{Step 4}: \(\Delta (\gamma)\) is a base of \(\Phi\). 

    \underline{Step 5}: Each base \(\Delta\) of \(\Phi\) has the form \(\Delta (\gamma)\) for some regular \(\gamma \in E\). 

    \underline{Proof of Step 1}: Suppose otherwise. Then \(\exists \alpha \in \Phi^+(\gamma)\) that cannot be expessed as a non-negative \(\mathbb{Z}\) linear combination of \(\Delta (\gamma)\).

    We can have multiple such \(\alpha \)'s. We pick the \(\alpha\) with the smallest \((\gamma , \alpha)\).

    Note that \(\alpha \notin \Delta (\gamma)\), since if \(\alpha \in \Delta (\gamma)\) then \(\alpha = 1\cdot \alpha\), which violates the assumption. 

    Thus, \(\alpha\) can be written as sum of two elements in \(\Phi^+(\gamma)\). Suppose \(\alpha = \beta_1 + \beta_2\) so that \(\beta_1, \beta_2 \in \Phi^+(\gamma)\). Then, \((\gamma , \alpha) = (\gamma , \beta_1) + (\gamma, \beta_2)\). Due to the minimality of \((\gamma ,\alpha)\), they are both non-negative \(\mathbb{Z}\)-linear conbination of \(\Delta (\gamma)\) which means so is \(\alpha\), a contradiction.

    \underline{Proof of Step 2}: Suppose otherwise. Then, \((\alpha , \beta) > 0\). \(\beta\) cannot be \(-\alpha\), thus \(\alpha - \beta\) is a root. Then either \(\alpha - \beta\) or \(\beta - \alpha\) is in \(\Phi^+(\gamma)\). WLOG \(\alpha - \beta \in \Phi^+(\gamma)\). Then \(\alpha  = \beta + (\alpha - \beta)\). Then \(\alpha\) is decomposable, which is a contradiction since \(\Delta (\gamma)\) consists of all indecomposable roots.

    \underline{Proof of Step 3}: Suppose \(\sum_{\alpha \in \Delta (\gamma), r_\alpha \in \mathbb{R}} r_\alpha \cdot \alpha = 0\). \(r_\alpha\) can be positive or negative. We redistribute so that both sides have positive coefficient:

    \[
        \varepsilon := \sum_\alpha s_\alpha \alpha = \sum_\beta t_\beta \beta
    \]

    Then, 

    \[
        0 \leq (\varepsilon , \varepsilon) = \sum_{\alpha , \beta} \underbrace{s_\alpha t_\beta}_{\geq 0} \underbrace{(\alpha , \beta)}_{\leq 0} \leq 0 
    \]

    Thus, \(\varepsilon = 0\). Now,

    \[
        0 = (\gamma , \varepsilon) = \sum_{\alpha} \underbrace{s_\alpha}_{\geq 0} \underbrace{(\gamma,\alpha)}_{>0} \geq 0 
    \]

    Thus, \(s_\alpha = 0\) for all \(\alpha\in \Delta(\gamma)\). This implies linear independence.
    
    \underline{Proof of Step 4}: Note that \(\Phi = \Phi^+(\gamma) \cup - \Phi^+(\gamma)\). 

    B2 is satisfied because of Step 1.

    Then \(\Delta (\gamma)\) spans \(E\). Step 3 implies \(\Delta (\gamma)\) is a basis of \(E\). Thus we have B1.

    \underline{Proof of Step 5}: Given \(\Delta\), we select \(\gamma \in E : (\alpha , \gamma)> 0 \forall \alpha \in \Delta\). B2 \(\implies \gamma\) is regular and \(\Phi^+ \subseteq \Phi^+(\gamma)\). Also, \(\Phi^- \subseteq - \Phi^+(\gamma)\). 

    Therefore, \(\Phi^+ = \Phi^+(\gamma)\). \(\Delta\) consists of indecomposable elements, that is \(\Delta \subseteq \Delta (\gamma)\).

    Coordinates are equal, therefore \(\Delta = \Delta (\gamma)\).

\end{proof}

\begin{definition}
    [Weyl Chambers]
    The connected components of \(E \setminus \bigcup_{\alpha \in \Phi}^{} P_\alpha\) are called the (open) Weyl Chambers of \(E\).
    
    The fundamental Weyl chamber associated to \(\gamma\) is the open Weyl chamber containing \(\gamma\). It is denoted by \(\mathcal{C}(\gamma)\).
    
    Furthermore, \(C(\gamma) = C(\gamma ^{\prime})\) implies \(\gamma\) and \(\gamma ^{\prime} \) are on the same side of each hyperplane \(P_\alpha\). This also means \(\Delta (\gamma) = \Delta (\gamma ^{\prime} )\), so the Weyl chambers are in 1-1 correspondence with the bases.
\end{definition}

For example: here is an open Weyl Chamber for \(A_2\):

\begin{center}
    \includegraphics[width=0.5\textwidth]{img/Weyl_chambers_for_A2}

    \(\mathcal{C}(\Delta)\)-fundamental Weyl chamber relative to the base \(\{ \alpha_1, \alpha_2 \}\). 
\end{center}

The Weyl group acts on the Weyl chambers by \(\sigma (\mathcal{C}(\gamma)) = \mathcal{C}(\sigma(\gamma))\). 

If \(\sigma \in \mathcal{W}\) and \(\gamma\) is regular.

Also, \(\mathcal{W}\) permutes bases. \(\sigma\) sends \(\Delta\) to \(\sigma(\Delta)\) which is another base.

Since \(\sigma(\Delta (\gamma)) = \Delta (\sigma (\gamma))\) because \((\sigma \gamma , \sigma \alpha ) = (\gamma , \alpha)\).

\section{Thursday, 10/17/2024, Weyl Group, Irr. Root System by Zoia}

\begin{lemma}
    Let \(\alpha\) be simple. Then \(\sigma_\alpha\) permutes the positive roots other than \(\alpha\).
\end{lemma}

\begin{corollary}
    Set \(\delta = \frac{1}{2} \sum_{\beta \prec 0} \beta\). Then,

    \[
        \sigma_\alpha (\delta) = \delta - \alpha \,\forall \alpha \in \Delta
    \]
\end{corollary}

\begin{lemma}
    Let \(\alpha_1, \cdots , \alpha_n \in \Delta\) [not necessarily distinct]. Write \(\sigma_i \coloneqq \sigma_{\alpha_i}\). If \(\sigma_1 , \cdots , \sigma_{t-1}(\alpha_t)\) is negative, then
    
    \[
        \exists s : 1 \leq s < t:\, \sigma_1 \cdots  \sigma_t = \sigma_1 \cdots \sigma_{s-1} \sigma_{s+1}\cdots \sigma _{t-1}
    \]


\end{lemma}

\begin{corollary}
    If \(\sigma = \sigma_1 \cdots \sigma_t\) is an exp for \(\sigma \in \mathcal{W}\), \(t\) is as small as possible theen \(\sigma(\alpha_t) \prec 0\).
\end{corollary}

\begin{proof}
    Suppose \(\sigma(\alpha_t) > 0\). Then,

    \[
        \underbrace{\sigma_1 \cdots \sigma_t}_{t \text{ factors}} = \underbrace{\sigma_1 \cdots \sigma_{s-1}\sigma_{s+1}\cdots \sigma_{t-1}}_{t-2 \text{ factors}}
    \]

    which contradicts minimality.
\end{proof}

\subsection*{The Weyl Group}

\begin{definition}
    \(\mathcal{W}\) is the subgroup of \(GL(E)\) generated by the reflection \((\sigma_\alpha)_{\alpha \in \Phi}\).
\end{definition}

\begin{theorem}
    Let \(\Delta\) be a base of \(\Phi\).

    \begin{enumerate}[label=\alph*)]
        \item If \(\gamma \in E\), \underline{\(\gamma\) is regular}, \(\exists \sigma \in \mathcal{W} : (\sigma(\gamma), \alpha) > 0 \, \forall \alpha \in \Delta\).
        \item If \(\Delta^{\prime}\) is another base of \(\Phi\), then \(\sigma(\Delta^{\prime}) = \Delta\) for some \(\sigma\in \mathcal{W}\).
        \item If \(\alpha\) is any root \(\implies \exists \sigma \in \mathcal{W} : \sigma(\alpha)\in \Delta\).
        \item \(\mathcal{W}\) generated by \(\sigma_\alpha \,(\alpha\in \Delta)\).
        \item If \(\sigma(\Delta)=\Delta, \sigma \in \mathcal{W}\) then \(\sigma = \operatorname{id}\). 
    \end{enumerate} 
\end{theorem}

\begin{proof}
    We consider the subgroup \(\mathcal{W}^{\prime}\)  generated by \(\sigma_\alpha( \alpha \in \Delta)\).

    For a, b, c we prove the theorem for \(\mathcal{W}^{\prime}\) and for d, e we prove that \(\mathcal{W}^{\prime} = \mathcal{W}\).

    a)

    \[
        \delta \coloneqq \frac{1}{2} \sum_{\alpha \prec 0} \alpha 
    \]

    Choose \(\sigma \in \mathcal{W}^{\prime}\) such that \((\sigma(\gamma), \delta)\) is as big as possible.

    If \(\alpha\) is simple then \(\sigma_\alpha \sigma \in \mathcal{W} ^{\prime} \implies (\sigma(\gamma), \delta) \geq (\sigma_\alpha \sigma(\gamma),\delta) = (\sigma(\gamma), \sigma_\alpha(\delta))=(\sigma(\gamma), \delta -\alpha) = (\sigma(\gamma),\delta) - (\sigma(\gamma),\alpha)\).

    Therefore, \((\sigma(\gamma),\alpha)\geq 0\).

    Furthermore, \((\sigma(\gamma),\alpha)\neq 0\) so we have strict inequality. Therefore,

    \[
        \forall \alpha \in \Delta, (\sigma(\gamma), \alpha) > 0
    \]

    Therefore, \(\sigma(\gamma)\) is in the fundamental Weyl chamber of \(\Delta\) and \(\sigma\) sends \(\mathfrak{C}(\gamma)\) to \(\mathfrak{C}(\Delta)\).

    b) Since \(\mathcal{W}^{\prime}\) permutes the Weyl chambers by \(a\), it also permutes the bases of \(\Phi\).

    c) Hyperplanes \(P_\beta\, (\beta \neq \pm \alpha)\) are distinct from hyperplane \(P_\alpha \implies \exists \gamma: \gamma \in P_\alpha, \gamma \notin P_\beta\). Lets choose \(\gamma^{\prime}\) so that \(\gamma^{\prime}\) is close to \(\gamma\) such that \((\gamma ^{\prime} , \alpha) = \varepsilon > 0\) while \(\vert (\gamma^{\prime} , \beta) \vert > \varepsilon\) for any \(\beta \neq \pm \alpha\).

    Then \(\alpha \in \Delta(\gamma^{\prime})\).

    d) We want to show that \(\mathcal{W} ^{\prime} = \mathcal{W}\). It is enough to show that each reflection \(\sigma_\alpha(\alpha \in \Phi)\) is in \(\mathcal{W}^{\prime}\).
    
    Find \(\sigma \in \mathcal{W} ^{\prime} \) such that \(\beta = \sigma (\alpha)\in \Delta \) using c. Then,

    \[
        \sigma_\beta = \sigma_{\sigma(\alpha)} = \sigma \sigma_\alpha \sigma ^{-1} \implies \sigma_\alpha = \sigma ^{-1} \sigma _\beta \sigma \in \mathcal{W} ^{\prime} 
    \]

    e) Let \(\sigma(\Delta) = \Delta\) but \(\sigma \neq \operatorname{id}\). If \(\sigma\) is written minimally as a product of simple reflections then we have contradiction from corollary 5.4.

\end{proof}

\subsection*{Irreducible Root System}

\(\Phi\) is irreducible if it cannot be partitioned intothe union of two proper subsets in the following way: each root in one set is orthogonal to each root in the other subset.

Exmaple: \(A_1, A_2, B_2, G_2\) are irreducible. \(A_1 \times A_1\) is not irreducible.

\underline{Claim}: \(\Phi\) is irreducible \(\iff \Delta\) cannot be \underline{partitioned}.

\begin{proof}
    \(\impliedby:\) Suppose \(\Phi = \Phi_1 \cup \Phi_2\) with \((\Phi_1, \Phi_2) = 0\).

    If \(\Delta\) is not wholly contained in \(\Phi_1\) or \(\Phi_2\) then it induces the partition in \(\Delta\). 

    Now WLOG suppose \(\Delta \subset \Phi_1\). Then, \((\Delta , \Phi_2) = 0\). Since \(\Delta\) spans \(E\).

    \(\implies:\) Let \(\Phi\) be irreducible but suppose \(\Delta = \Delta_1 \cup \Delta_2\) with \((\Delta_1, \Delta_2) = 0\).

    Each root is conjugate to a simple root (by theorem). Then,

    \[
        \Phi = \Phi_1 \cup \Phi_2
    \]

    where \(\Phi_i\) is the set of roots that are conjugates with those in \(\Delta_i\).

    Since \(\mathcal{W}\) is generated by the \(\sigma_\alpha\) where \(\alpha \in \Delta\), it follows that each root in \(\Phi_i\) can be obtained from obtained from \(\Delta_i\) by \(+\) or \(-\) elements of \(\Delta_i\).

    Therefore, \(\Phi_i\) lies in the subspace \(E_i\) of \(E\) spanned by \(\Delta_i\).

    Then, \((\Phi_1, \Phi_2) = 0\).
    
    Since \(\Phi\) is irreducible, it follows that \(\Phi_1 = \varnothing \) or \(\Phi_2 = \varnothing \).

    Therefore, \(\Delta_1 = \varnothing\) or \(\Delta_2 = \varnothing\).

\end{proof}

\begin{lemma}
    Let \(\Phi\) be irreducible. Then relative to the partial ordering \(\prec\), there exists a \underline{unique maximal root} \(\beta\).

    If \(\beta = \sum_{\alpha} k_\alpha \alpha \,(\alpha \in \Delta)\) then all \(k_\alpha > 0\).
\end{lemma}

\begin{lemma}
    Let \(\Phi\) be irreducible. Then \(\mathcal{W}\) acts irreducibly on \(E\). In particular, the \(\mathcal{W}\)-orbit of a root \(\alpha\) spans \(E\).
\end{lemma}

\begin{lemma}
    Let \(\Phi\) be irreducible. Then at most two root lengths occur in \(\Phi\) and all roots of this length are conjugates under \(\mathcal{W}\).
\end{lemma}

\begin{lemma}
    Suppose \(\Phi\) is irreducible with two distinct root lengths. Then the maximal root \(\beta\) of lemma 5.6 is long.
\end{lemma}

\section{Thursday, 10/24/2024, Decomposing into Irr. by Hyeonmin}

\underline{Facts}:

\begin{enumerate}[label=\arabic*)]
    \item Lemma 9.2 and (R3): \(\forall \alpha , \beta \in \Phi , \forall \sigma \in \mathcal{W}, \langle \beta , \alpha \rangle = \langle \sigma \beta, \sigma \alpha \rangle\).
    \item Table 1 in 9.4: \(\forall \alpha ,\beta \in E, \alpha \neq \beta, \langle \alpha , \beta \rangle \langle \beta , \alpha \rangle = 0, 1, 2, 3\).
    \item Lemma 10.1: \(\forall \alpha , \beta \in \Delta, \alpha \neq \beta, \langle \alpha , \beta \rangle \leq 0\).
    \item Theorem 10.3b: \(\mathcal{W}\) acts transitively on the bases. 10.3c: \(\forall \alpha \in \Phi , \exists \sigma \in \mathcal{W}\) such that \(\sigma(\alpha)\in \Delta\). 10.3d: \(\mathcal{W}\) is generated by \(\sigma_\alpha (\alpha \in \Delta)\).
    \item Claim 10.4: \(\Phi\): irreducible \(\iff \Delta\) canot be partitioned into proper \(\Delta _1 \cup \Delta_2\) such that \((\Delta_1, \Delta_2)=0\).
\end{enumerate} 

\subsection*{Classification}

Fix \(\Delta \subseteq \Phi\) and let \(l = \dim_\mathbb{R} E\).

\begin{definition}
    Fix an ordering \((\alpha_1, \cdots , \alpha_l)\) of \(\Delta\).
    
    Then \((\langle \alpha_i, \alpha_j \rangle)_{ij}\) is called the \underline{cartan matrix of \(\Phi\)}.
    
    The entries are called the \underline{Cartan integers}.

\end{definition}

\begin{example}
    In \(B_2\) the Cartan matrix is:

    \[
        \begin{bmatrix}
            2 &  -1 \\
            -2 &  2 \\
        \end{bmatrix}
    \]
\end{example}

\begin{remark}
    \begin{enumerate}[label=\arabic*)]
        \item The Cartan matrix depends on the chosen ordering.
        \item The Cartan matrix is independent of the choice of \(\Delta\). This is because, if \(\Delta^{\prime}\) is another base, since \(\sigma\) acts transitively, there exists \(\sigma \in \mathcal{W}\) such that \(\sigma \Delta = \Delta^{\prime}\). Using the fact \(\langle \alpha_i, \alpha_j \rangle = \langle \sigma \alpha_i, \sigma \alpha_j \rangle \) we see that the matrices are the same.
        \item The Cartan Matrix is nonsingular. This is because:
        
        \[
            (\langle \alpha_i, \alpha_j \rangle)_{i,j} \cdot \operatorname{diag}\left( \frac{(\alpha_i, \alpha_i)}{2}, \cdots , \frac{(\alpha_l, \alpha_l)}{2} \right) = \underbrace{((\alpha_i, \alpha_j))_{ij}}_{\text{nonsingular since inner product of basis}}  
        \]
    \end{enumerate} 
\end{remark}

\begin{proposition}[11.1]
    Let \((\Phi^{\prime} , E^{\prime})\) be another root system. Suppose it has base \(\Delta^{\prime} = \{ \alpha_1^{\prime} , \cdots , \alpha_s^{\prime} \}\) such that \(\langle \alpha_i, \alpha_j \rangle = \langle \alpha_i^{\prime} , \alpha_j^{\prime} \rangle\).

    Then the bijection \(\underset{\alpha_a}{\Delta} \underset{\mapsto}{\to} \underset{\alpha_a^{\prime}}{\Delta ^{\prime} } \) extends unique to a root system isomorphism \(\phi : (\Phi , E) \to (\Phi ^{\prime} , E^{\prime} )\).

    Therefore, the Cartan matrix of \(\Phi\) determines \(\Phi\) upto isomorphism.
\end{proposition}

\begin{proof}
    \(\Delta , \Delta^{\prime} \) are both basis \(\implies \exists\) vector space isomorphism \(\phi: E \to E^{\prime}\) such that \(\alpha_a \to \alpha_a^{\prime}\).
    
    \(\forall i,j\, \sigma_{\phi(\alpha_i)}(\phi(\alpha_j))=\phi(\alpha_j)- \frac{\langle\phi(\alpha_j), \phi(\alpha_i)\rangle}{\langle \alpha_j, \alpha_i \rangle }\phi(\alpha_i) = \phi(\alpha_j - \langle \alpha_j, \alpha_i \rangle \alpha_i) = \phi(\sigma_{\alpha_i}(\alpha_j))\)
    
    Therefore, we have the commutative diagram:

    \begin{center}
        \begin{tikzcd}
            E \ar[r, "\phi"] \ar[d, "\sigma_\alpha"] & E^{\prime} \ar[d, "\sigma_{\alpha^\prime}"] \\ E \ar[r, "\phi"] & E^\prime
        \end{tikzcd} \(\quad\)  (A)
    \end{center}

    \(\alpha \in \Delta\) and \(\forall x\in E, \langle x, \alpha \rangle = \langle \phi(x), \phi(\alpha) \rangle \, (B)\)
    
    A and since \(\mathcal{W}\) is generated by \(\sigma_\alpha\) we have for all \(\sigma \in \mathcal{W}\) we have:

    \begin{center}
        \begin{tikzcd}
            E \ar[r, "\phi"] \ar[d, "\sigma"] & E^{\prime} \ar[d, "\sigma^\prime"] \\ E \ar[r, "\phi"] & E^\prime
        \end{tikzcd}
    \end{center}

    Where \(\sigma = \sigma_{\alpha_{l_1}}\cdots \sigma_{\alpha_{l_k}}\) and \(\sigma^{\prime} = \sigma_{\alpha_{l_1^{\prime}}}\cdots \sigma_{\alpha_{l_k^{\prime}}}\).

    Therefore \(\phi \circ \sigma \circ \phi ^{-1} = \sigma ^{\prime} \in \mathcal{W} \quad (D)\).

    Claim 1: \(\phi(\Phi) \subseteq \Phi ^{\prime} \) 
    
    Let \(\beta \in \Phi \implies \exists \sigma \in \mathcal{W} , \exists \alpha \in \Delta\) such that \(\sigma \alpha = \beta\) 
    
    Also, \(\phi(\beta) = \underbrace{(\phi \circ \sigma \circ \phi ^{-1})}_{\in \mathcal{W} ^{\prime} }\underbrace{(\phi (\alpha))}_{\in \Phi ^{\prime}}\in \Phi ^{\prime} \)
    
    Claim 2: \(\forall \beta , \gamma \in \Phi , \langle \gamma , \beta \rangle = \langle \phi(\gamma), \phi(\beta) \rangle \).

    Since \(\mathcal{W}\) is generated by reflections \(\exists \sigma \in \mathcal{W} , \exists \alpha \in \Delta\) such that \(\sigma \alpha =\beta\). Then,

    \[
        \langle \gamma , \beta \rangle = \langle \sigma ^{-1} \gamma , \alpha \rangle \underset{B}{=} \langle \phi \circ \sigma ^{-1} (\gamma), \phi(\alpha) \rangle = \langle \sigma ^{\prime} \circ \phi \circ \sigma ^{-1} (\gamma), \sigma^{\prime} \circ \phi(\alpha) \rangle = \langle \phi(\gamma), \phi(\beta) \rangle  
    \]
\end{proof}

\begin{definition}
    Fix \(\Delta = \langle \alpha_1, \cdots , \alpha_l \rangle \) a base. The \underline{Coxeter graph} of \(\Phi\) consists of \(l\) vertices correlated to \(\Delta\) and \(\langle \alpha_i, \alpha_j \rangle \langle \alpha_j, \alpha_i \rangle \) edges between the \(i\)'th and \(j\)'th vertices \((i\neq j)\).
\end{definition}

\begin{remark}
    This graph is independent of \(\Delta\). Since \(\Delta ^{\prime}\) another base \(\implies \exists \sigma \in \mathcal{W}\) such that \(\sigma \Delta = \Delta ^{\prime}  \implies \langle \alpha_i, \alpha _j \rangle = \langle \sigma \alpha_i, \sigma \alpha_j \rangle\).

    Also, we have \(\langle \alpha_i, \alpha_j \rangle \langle \alpha_j, \alpha_i \rangle = 0,1,2,3\).

\end{remark}

e.g. [insert fig table]

We need more information to recover Cartan integer.

We cannot recover \(\langle \alpha_i, \alpha_j \rangle\) when \(\langle  \rangle = 2,3\).

\begin{definition}
    The \underline{Dynkin diagram} of \(\Phi\)is the Coxeter graph adding an arrow pointing to the shorter length root.

    e.g [insert picture and matrix for B2 fig]
\end{definition}

\begin{proposition}
    [11.3] \(\Phi\) decomposes uniquely as the union of irreducible root system \(\Phi_i\) in subspaces \(E_i \subset E\) such that \(E = E_1 \oplus \cdots \oplus E_t\) [orthogonal direct sum].
\end{proposition}

\begin{proposition}
    [Ex 9.1] \(E^{\prime} \subset E\): a subspace. If \(\sigma_\alpha (E^{\prime}) \subseteq E^{\prime}\) then either \(\alpha \in E^{\prime}\) or \(E^{\prime} \subseteq P_\alpha\) 
\end{proposition}

\begin{proof}
    Suppose \(E^{\prime} \subsetneq P_\alpha\). Then \(\exists \beta \in E^{\prime}\) such that \((\alpha ,\beta) \neq 0\).

    \(\sigma_\alpha (\beta) = \beta  - \langle \beta , \alpha \rangle \alpha \in E^{\prime} \implies \alpha \in E^{\prime}\).
\end{proof}

\begin{proof}
    (Of 11.3)

    \(\Delta\) cannot be partitioned into proper \(\Delta_1 \cup \Delta_2\) such that \((\Delta_1, \Delta_2) = 0 \iff\) the coxeter graph of \(\Phi\) is connected (A).
    
    [insert picture fig]

    Assume that the coxeter graph consists of connected components \(C_1, \cdots , C_t\).

    Let \(\Delta = \Delta_1 \cup \cdots \cup \Delta_t\) be the partition so that \(\Delta_i\) correlates to \(C_i\).

    \(A \implies \Delta_i\) are mutually orthogonal. Define \(E_i = \operatorname{span}_\mathbb{R}(\Delta_i)\).

    Therefore, \(E = E_1 \oplus \cdots \oplus E_t\) [orthogonal]. (B)

    Define \(\Phi_i = \{ \alpha \in \Phi \mid \alpha : \text{a \(\mathbb{Z}\)-linear combination of \(\Delta_i\)}  \} \).

    Then, \((\Phi_i, E_i)\) is a root sytem [by checking the axioms].

    \(\Delta_i \subseteq \Phi_i\) is a base (again checking the axioms).

    Therefore, \(\Phi_i\) are irreduible.
    
    Finally, we want to check \(\Phi = \Phi_1 \cup \cdots \cup \Phi_t\).

    The Weyl group \(\mathcal{W}_i\) corresponding to \(\Phi_i\) is the subgroup of \(\mathcal{W}\) generated by \(\sigma_\alpha \) where \(\alpha \in \Delta_i\).

    B \(\implies \sigma_\alpha\) acts trivially on \(E_i\) for any \(\alpha \in \Delta_j, i \neq j\). (C)

    \(E_i\) is \(\mathcal{W}_i\) invariant, so \(\sigma_\alpha (E_i) \subseteq E_i \forall \alpha \in \Delta_i \overset{C}{\implies} E_i\) is \(\mathcal{W}\)-invariant.

    Thus, \(\sigma(E_i) \subseteq E_i\) for any \(\sigma\in \mathcal{W}\) 
    
    Now we use Exercise 9.1.

    \(\supseteq\) is trivial by definition.

    \(\subseteq\) \(\alpha \in \Phi \underset{D}{\implies} \sigma_\alpha(E_i) \subseteq E_i \overset{\text{Ex 9.1}}{\implies } \exists 1 \leq j \leq t\) such that \(\alpha \in E_j\) but \(\alpha\notin E_i \forall i \neq j\).
    
    Thus, \(\alpha \in \operatorname{span}_{\mathbb{R}}(\Delta_i) \cap \Phi  \implies \alpha\) is a \(\mathbb{Z}\)-linear combination of \(\Delta\) in \(\operatorname{span}(\Delta_i)\).

    Therefore, \(\alpha\) is a \(\mathbb{Z}\)-linear combination of \(\Delta_i\).

    This is the definition of \(\Phi_i\).

    Therefore, \(\alpha \in \Phi_i\).
    
\end{proof}

\begin{theorem}
    [Classification Theorem]

    Let \(\Phi\) be an irreducible root system. Then, \(\Phi\) can only have \(A-G\) type Dynkin diagrams.
\end{theorem}

\section{Thursday, 10/31/2024, Irr. rootot System by Hyeonmin}

\begin{theorem}
    [11.4]

    If \(\Phi\) is an irreducible root system, its Dynkin diagram is one of the following:

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{img/dynkin}
        \caption{Dynkin Diagrams}
        \label{fig:dynkin}
    \end{figure}
\end{theorem}

\begin{proof}
    \underline{Suffices to Show}: Coxeter graph is one of the following:

    \[
        A_l, B_l (= C_l), D_l, E_{6,7,8}, F_4, G_2
    \]

    So we can ignore the length of the roots. We work with unit vectors.

    \begin{definition}
        Let \(E\) be euclidean space of dimension \(m\) and let \(\mathfrak{A} = \{ \varepsilon_1, \cdots , \varepsilon_n \} \subseteq E\) be \underline{admissible} if:

        \begin{enumerate}[label=\arabic*)]
            \item Vectors are linearly independent.
            \item Vectors are unit vectors.
            \item \((\varepsilon_i, \varepsilon_j)\leq 0\) if \(i \neq j\).
            \item \(4(\varepsilon_i, \varepsilon_j)^2 = 0,1,2\) or \(3\). 
        \end{enumerate} 

    \end{definition}

    Then, \underline{The graph \(\Gamma\) of \(\mathfrak{A}\)[coxeter graph]} has \(n\) vertices and \(4(\varepsilon_i, \varepsilon_j)^2\) as edges.

    \underline{Existence}:

    \[
        \Delta \supseteq \{ \alpha_1, \cdots , \alpha_n \} \implies \left\{ \frac{\alpha_1}{\sqrt{(\alpha_1, \alpha_1)}}, \cdots , \frac{\alpha_n}{\sqrt{(\alpha_n, \alpha_n)} } \right\} \coloneqq \{ \varepsilon_1, \cdots , \varepsilon_n \} \, \text{admissible}. 
        \]

    \[
        4 (\varepsilon_i, \varepsilon_j)^2 = \frac{4(\alpha_i, \alpha_j)^2}{(\alpha_i, \alpha_j)(\alpha_j, \alpha_i)} = \langle \alpha_i, \alpha_j \rangle \langle \alpha_j, \alpha_i \rangle
    \]

    \begin{enumerate}[label=\arabic*)]
        \item A subset \(\mathfrak{A} ^{\prime} \subseteq \mathfrak{A}\) is still admissible.
        \item \#\{pairs of vertices in \(\Gamma\) connected by each other\} \(< n\).
        
        Since set \(\varepsilon \coloneqq \sum_{i=1}^n \varepsilon_i \neq 0\). Thus \(0 < (\varepsilon, \varepsilon) = \underbrace{n}_{=\sum_{i} (\varepsilon_i, \varepsilon_i)} + \sum_{i<j} 2 (\varepsilon_i, \varepsilon_j)\).
        
        Suppose \((\varepsilon_i, \varepsilon_j) < 0\).

        \(4(\varepsilon_i, \varepsilon_j)^2 = 1,2,3 \implies 2 (\varepsilon_i, \varepsilon_j) \leq -1\).

        \item \(\Gamma\) contains no cycles.
        
        Let \(\Gamma^{\prime} \subseteq \Gamma\) be a vertix on \(k\) vertices.

        Then \#\{such pairs from (2) in \(\Gamma^{\prime}\)\} \(\geq k\). Contradiction by 2.
        
        \item \#\{edges originated at a vertex (\(\varepsilon\)) of \(\Gamma\)\} \(\leq 3\)
        
        Let \(\varepsilon, \eta_1, \cdots , \eta_k \in \mathfrak{A}\) be distinct such that \((\varepsilon, \eta_i)\neq 0\).

        (3) \(\implies (\eta_i, \eta_j) = 0 \forall i \neq j\).
        
        Set \(\eta_0^{\prime} \coloneqq \epsilon - \sum_{i=1}^k (\varepsilon, \eta_i)\eta_i\) and \(\eta_0 \coloneqq \frac{\eta_0^{\prime}}{(\eta_0^{\prime}, \eta_0^{\prime} )}\). Then,

        \begin{itemize}
            \item \((\eta_0^{\prime} , \eta_i) = (\varepsilon, \eta_i) - (\varepsilon, \eta_i)(\eta_i, \eta_i) = 0 \implies (\eta_0, \eta_i) = 0\).
            \item \(\eta_0 \in \operatorname{span}\{ \varepsilon , \eta_1, \cdots , \eta_k \} \implies (\eta_0, \varepsilon) \neq 0\).
            \item \((\eta_0^{\prime} , \eta_0^{\prime}) = (\varepsilon, \eta_0^{\prime}) \implies \sum_{i=0}^k (\varepsilon, \eta_i) \eta_i = (\varepsilon , \eta_0) \eta_0 + \sum_{i=1}^k (\varepsilon , \eta_i)\eta_i\)
            
            \(= \frac{(\varepsilon, \eta_0^{\prime})}{(\eta_0^{\prime} , \eta_0^{\prime})}\eta_0^{\prime} + \sum_{i=1}^k (\varepsilon , \eta_i) \varepsilon_i = \varepsilon\).

            \(\implies 1 = (\varepsilon, \varepsilon) =\sum_{i=0}^k (\varepsilon, \eta_i)^2 > \sum_{i=1}^k (\varepsilon, \eta_i)^2 \implies 4 > \sum_{i=1}^k 4 (\varepsilon, \eta_i)^2\).
        \end{itemize}
        
        \item The only graph \(\Gamma\) containing a triple edges is \(G_2\).
        
        \item Let \(\{ \varepsilon_1, \cdots , \varepsilon_k \} \subseteq \mathfrak{A}\) have a subgraph
            
        [insert pic like A1 with veps 1, ..., veps k]

        \(\mathfrak{A}'= (\mathfrak{A} \setminus \{ \varepsilon_1, \cdots , \varepsilon_k \}) \cup \{ \varepsilon \}\) is admissible where \(\varepsilon = \sum_{i=1}^k \varepsilon_i\). 
            
        Condition 1 is satisfied automatically.

        Condition 2: \(\varepsilon\) is a unit: \(2 (\varepsilon_i, \varepsilon_{i+1}) = -1 \implies (\varepsilon , \varepsilon) = k + \sum_{i=1}^{k-1} (\varepsilon_i, \varepsilon_{i+1}) = 1\) so it holds.
            
        Condition 3: \(\eta \in \mathfrak{U} \setminus \{ \varepsilon_1, \cdots , \varepsilon_k \} \) can be connected to at most one of \(\varepsilon_1, \cdots , \varepsilon_k\). 3 \(\implies (\eta, \varepsilon) = 0\) or \((\eta, \varepsilon) = (\eta, \varepsilon_j) \leq 0 \implies (\eta, \varepsilon) \leq 0\).

        Condition 4: \(4(\eta,\varepsilon)^2 = 0\) or \(4(\eta, \varepsilon_i)^2 = 0,1,2\) or \(3\)
            
        
    \item \(\Gamma\) contains no subgraph of the form:
        
    [insert figure]

    \item Any connected \(\Gamma\) of an admissible set has one of the following forms:
        
    [insert figure]

    \item The second type in 8: \(B_l(= C_l), F_4\).
    
    Set \(\varepsilon \coloneqq \sum_{i=1}^p i \varepsilon_i, \eta \coloneqq \sum_{i=1}^q i \eta_i\).

    Then \(2 (\varepsilon_i, \varepsilon_{i+1}) = -1 = 2(\eta_j, \eta_{j+1})\).
    
    Then, \((\varepsilon , \varepsilon) = \sum_{i=1}^p i^2 - \sum_{i=1}^{p-1} i(i+1) = \frac{p(p+1)}{2}\), and \((\eta, \eta) = \frac{q(q+1)}{2}\). (A)

    \(4(\varepsilon_p, \eta_q)^2 = 2 \implies (\varepsilon, \eta)^2 = (p \varepsilon_p, q \eta_q)^2 = \frac{p^2 q^2}{2}\) (B).

    The Schwarz inequality of linear independent \(\varepsilon \cdot \eta : (\varepsilon , \eta)^2 < (\varepsilon, \varepsilon)(\eta, \eta)\).

    A and B \(\implies \frac{2 p^2 q^2}{2} < \frac{pq(p+1)(q+1)}{4} \implies pq - p - q - 1 < 0 \implies (p-1)(q-1) < 2\)
    
    \(\implies \underbrace{p=q=2}_{F_4}\) or \(\underbrace{p=1 \text{ or } q=1}_{B_l}\).
    
    \item The 3rd type in 8: \(D_l, E_6, E_7, E_8\).

    Set up \(\eta^i \coloneqq \sum_{j} \eta_j^i \implies (\eta^i, \eta^j) = 0, (\varepsilon , \eta^i) \neq 0\).
    
    Applying the method in the proof of (4),

    \(\eta^{0\prime} \coloneqq \varepsilon - \sum_{i=1}^3 \frac{(\varepsilon, \eta^i)}{(\eta^i, \eta^i)}\eta^i\) and \(\eta^0 \coloneqq \frac{\eta^{0\prime}}{\sqrt{(\eta_0^{\prime}, \eta_0^{\prime})} }\)  
    
    It is easy to show that:

    \begin{itemize}
        \item \((\eta^0, \eta^i) = 0\)
        \item \((\varepsilon, \eta^0) \neq 0\)
        \item \(\varepsilon = (\varepsilon, \eta^0)\eta^0 +\sum_{i=1}^3 \frac{(\varepsilon, \eta^i)}{(\eta^i, \eta^i)}\eta^i\)  
    \end{itemize} 

    Then \(1 = (\varepsilon , \varepsilon) > \sum_{i=1}^3 \frac{(\varepsilon, \eta^i)^2}{(\eta^i, \eta^i)}\) by the same reason in (4).

    \((\eta^{\prime} , \eta^{\prime}) = \frac{p(p-1)}{2}\implies \frac{(\varepsilon , \eta^{\prime})^2}{(\eta^{\prime} , \eta^{\prime})} = \frac{p-1}{2p} = \frac{1}{2}\left( 1 - \frac{1}{p} \right)\). Apply \(\eta^2, \eta^3\).
    
    \(\implies 1 > \sum \frac{(\varepsilon, \eta_i)^2}{(\eta^i, \eta^i)} = \frac{1}{2}\left( 3 - \frac{1}{p} - \frac{1}{q}- \frac{1}{r} \right) \implies \frac{1}{p} + \frac{1}{q} + \frac{1}{r} > 1\) (C).
    
    WLOG assume \(\frac{1}{p} \leq \frac{1}{q} \leq \frac{1}{r} \leq \frac{1}{2}\) (D) [if one of them is \(1\) graph is \(A_l\)].

    C, D \(\implies \frac{1}{3} < \frac{1}{r} \leq \frac{1}{2} \implies r = 2 \implies \frac{1}{p} + \frac{1}{q} > \frac{1}{2}\) (E).

    D, E \(\implies \frac{1}{4} < \frac{1}{q} \leq \frac{1}{2} \implies q = 2, 2 \leq p \implies D_l\) or \(q=3, p = 3,4,5 \implies E_6, E_7, E_8\).

    \end{enumerate} 
    
    \underline{Construction}:

    [matrices for \(A_l, B_l, C_l, D_l\)]

    Let \(E = \mathbb{R}^n\) with the usual inner product and standard basis \(\{ \varepsilon_1, \cdots , \varepsilon_n \}\). Let \(I =\) \{\(\mathbb{Z}\)-linear combination of \(\{ \varepsilon_1, \cdots ,\varepsilon_n \}\)\}.
    
    \(A_l (l \geq 1) E:\) a \(l\)-subspace of \(\mathbb{R}^{l+1}\) orthogonal to \(\varepsilon_1 + \cdots + \varepsilon_{l+1}\).
    
    \(I^{\prime} = I \cap E\).

    \(\Phi = \{ \alpha \in I^{\prime} \mid (\alpha, \alpha) = 2 \} = \{ (\varepsilon_i - \varepsilon_j), i \neq j\}\).

    Root system: \(\Delta = \{ \varepsilon_1 - \varepsilon_2, \cdots , \varepsilon_l - \varepsilon_{l+1} \} \) 

    Weyl Group: \(\sigma_{\varepsilon_i - \varepsilon_{i+1}}: \begin{matrix}
        \varepsilon_i \mapsto \varepsilon_{i+1}  \\
        \varepsilon_{i+1} \mapsto \varepsilon_i   \\
    \end{matrix} \leftrightarrow (i, i+1) \).
    
    Thus, \(\mathcal{W} \cong S_{l+1}\).

    \(B_l(l \geq 2) E = \mathbb{R}^l\)

    \(\Phi_B = \{ \alpha \in I \mid (\alpha , \alpha) = 1 \text{ or } 2 \} = \{ \pm \varepsilon_i, \pm (\varepsilon_i \pm \varepsilon_j), i \neq j \}\).

    \(\Delta = \{ \varepsilon_1 - \varepsilon_2 , \cdots , \varepsilon_{l-1} - \varepsilon_l, \varepsilon_l \} \) a base.

    Weyl Group \(\mathcal{W}\):

    \(\sigma_{\varepsilon_i - \varepsilon_{i+1}} \leftrightarrow (i, i+1)\)
    
    \(\sigma_{\varepsilon_l} \varepsilon_l \mapsto - \varepsilon_l \)
    
    \(\mathcal{W} \cong (\mathbb{Z} / 2\mathbb{Z})^l \rtimes S_l\).

    \(D_l (l \geq 4) E = \mathbb{R}^l, \Phi = \{ \alpha \in I \mid (\alpha , \alpha) = 2 \} = \{\pm (\varepsilon_i \pm \varepsilon_j)\}\).

    \(\Delta = \{ \varepsilon_1 - \varepsilon_2 , \cdots , \varepsilon_{l-1} - \varepsilon_l, \varepsilon_{l-1} + \varepsilon_l \} \)
    
    \(\sigma_{\varepsilon_{i} - \varepsilon_{i+1} }: (i, i+1)\)
    
    \(\sigma_{\varepsilon_{l-1} + \varepsilon_l} \): \(\varepsilon_{l-1} \mapsto - \varepsilon_l, \varepsilon_l \mapsto - \varepsilon_{l-1}\).

    \(\mathcal{W} \cong (\mathbb{Z} / 2\mathbb{Z})^{l-1} \rtimes S_l\).
    

\end{proof}

\subsection{12.2 Automorphism}

Claim 1: \(\operatorname{Aut} \Phi \cong \Gamma \rtimes \mathcal{W}\) where \(\Gamma = \{ \tau \in \operatorname{Aut} \Phi \mid \tau(\Delta)  \Delta \} \).

Claim 2: \(\Gamma\) may be identified with automorphims of its dynkin diagram of \(\Phi\).

\section{Thursday, 12/5/2024, Cartan Subalgebras (CSA) by Rostyslav}

2+2 Definitions.

General Lie Algebra:

\begin{enumerate}[label=\roman*)]
    \item In terms of a normalizer
    \item In terms of Engel subalgebra 
\end{enumerate} 

Semisimple Lie Algebra:

\begin{enumerate}[label=\roman*)]
    \item Maximal toral subalgebras
    \item Maximal centralizer 
\end{enumerate} 

If \(x\in \operatorname{End} (V), V = \bigoplus V_a(x), V_a(x) = \ker (x-a \operatorname{id}_{})^m\) where \(m\) is a multiplicity of root of char. poly.

We have \(\eval{x}_{v_a(x)}^{} = \underbrace{a}_{\text{scalar}} + \underbrace{n}_{\text{nilpotent}} \).

Then, \(L = \sqcup_{a\in F} L_a (\operatorname{ad} x) = L_u (\operatorname{ad} x) \oplus L_n(\operatorname{ad} x)\) 

\begin{lemma}
    If \(a,b\in F\) then,

    \[
        [L_a(\operatorname{ad} x), L_b(\operatorname{ad} x)] \subset L_{a+b}(\operatorname{ad} x)
    \]

    In particular, when \(L_t(\operatorname{ad} x)\) is a subalgebra of \(L, \operatorname{char} F = 0, a \neq 0\) then,
    
    \[
        \forall l \in L_a(\operatorname{ad} x)\, l \text{ is nilpotent} 
    \]
\end{lemma}

Fact: (simple) adjoints are derivations

\[
    (\operatorname{ad} x - (a+b))^m [yz] = \sum_{i=0}^m \binom{m}{i}[(\operatorname{ad} x - a)^i (y), (\operatorname{ad} x - b)^{m-i}(z)]  
\]

For \(m\) sufficiently large all elements on the right well vanish.

\begin{definition}
    [Engel Subalgebra] is \(L_0(\operatorname{ad} x)\).
\end{definition}

\begin{lemma}
    [15.2.A] Let \(K \subset L\)-subalgebra. Choose \(z\in K\) such that \(L_0(\operatorname{ad} z)\) is minimal among \(L_0(\operatorname{ad} x)\) for all \(x\in K\). Suppose \(K \subset L_0(\operatorname{ad} z)\). Then \(L_0(\operatorname{ad} z) \subset L_0(\operatorname{ad} x) \, \forall x\in K\).  
\end{lemma}

Let \(x\in K\) fixed, but arbitrary. Consider a family of endomorphisms of \(L \{ \operatorname{ad} (z+cx) \mid c\in F \} \). \(K_0 = L_0(\operatorname{ad} z)\) is a subalgebra of \(L\) including \(K\) therefore these endoomorphisms will stabilize \(K_0(=L_0(\operatorname{ad} z))\).

Can induce endomorphism of \(\eval{L}_{K_0(=L_0(\operatorname{ad} z))}^{} \).

Endomorphism is \(\operatorname{ad} (z + cx)\). Let \(f,g\) be char. poly in \(K_0\) over \(L / K\) and let \(n = \dim K_0, n - \dim L\).

\[
    f(T,c) = T^r + f_1(c) T^{n-1} + \cdots + f_n(c)
\]

\[
    g(T,c) = T^{n-r} + g_1(c) + T^{n-r-1} + \cdots g_{n-r}(c)
\]

\(f_i, g_i\) are polynomials.

By definition, eigenvalue \(0\) appears only in \(K_0\) when \(T=0, g_{n-r}\) is not identically zero on \(F\). Lets take \(c_1, \cdots , c_{r+1}\) not zeros of \(g_{n-r}\). To say \(g_{n-r}(0) = 0 \iff\) \(0\) is not an eigenvalue of \(\operatorname{ad} (z+cx)\) on the quotient space.

\(\implies \forall L_0(\operatorname{ad} (z+cx))\) lie in the subspace of \(K_0\).

But \(K_0\) is minimal.

\(K_0 = L_0(\operatorname{ad} z) = L_0(z+c_ix)\, 1 \leq i \leq r+1\).

The only eigenvalues \(\operatorname{ad}(z+cx)\) has is \(0\).

\(\implies f(T,c_i) = T^r, f_i = f(T,c_i)\).

\(\forall f_i\) has \(r+n\) distinct zeros \(\implies \forall f_i\) are identically zero.

\(L_0(\operatorname{ad} (z+cx)) \supset K_0 \forall c \in F\).

Replace \(x\) with \(x-z, c=1\).

\(L_0(\operatorname{ad} x)  \supset K_0 = L_0(\operatorname{ad} x)\) so we're done.

\begin{lemma}
    [15.2.B] If \(K \subset L\) subalgebra and \(L_0(\operatorname{ad} x) \subset K \implies K\) is self normalizing. In particular, Engel subalgebras are self-normalizing.  
\end{lemma}

\(L_0(\operatorname{ad} x) \subset K \implies \operatorname{ad} x\) acts on \(N_L(K) / K\) without an eigenvalue \(0\) in \(\ker = 0\).

\(x\in K \, [N_L(K)x] \subset K \implies \operatorname{ad} x\) acts trivially on \(N_L(K) / K \implies N_L(K) = K\).

\begin{definition}
    [Cartan Subalgebra] Cartan Subalgebra is a nilpotent subalgebra of \(L\) that is self-normalizing.
\end{definition}

\begin{theorem}
    [15.3] Let \(H\)-subalgebra of \(L\). \(H\) is a CSA \(\iff H\) is a minimal Engel subalgebra.
\end{theorem}

\(\impliedby:\) Assume it is a minimal Engel subalgebra. Then, \(H = L_0(\operatorname{ad} z) \overset{15.2.B}{\implies} H\) is self-normalizing. \(\overset{15.2.A}{\implies} L_0(\operatorname{ad} z) \subset L_0(\operatorname{ad} x)\).

We apply \underline{Engel's Theorem} which states if \(\forall x\in L \operatorname{ad} x\) is nilpotent then \(L\) is nilpotent.

\(\forall x\in H\) in particular \(\operatorname{ad}_H x\) is nilpotent so \(H\) is nilpotent.

\(\implies:\) Let \(H\) be CSA, \(H\) is nilpotent by defintion. \(H \subset L_0(\operatorname{ad} x)\). We want to prove \(\exists z\) such that \(H = L_0(\operatorname{ad} z)\).

Lets assume that is not the case.

Take \(L_0(\operatorname{ad} z)\) smallest, \(\overset{15.2.A}{\implies} L_0(\operatorname{ad} z) \subset L_0(\operatorname{ad} x)\).

\(L_0(\operatorname{ad} z) / H\) here \(x\in H\) will act as a nilpotent.

\(H\) annihilates some \(y+H\) where \(y\neq 0\).

\(\exists y\in H\) such that \([Hy] \subset H\). But \(H\) is self normalizing. Contradiction! So we're done.

\end{document}